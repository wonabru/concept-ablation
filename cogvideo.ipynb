{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fabd25df-3d6e-41f7-9623-3098f062ee7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
      "/usr/local/lib/python3.11/dist-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e01f298b0d34544be1e3aa734daa911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549ea2879d6441e5b2e67900daa37af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d25e1551504a7f88839768a88ce511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "Found an existing imageio backend in your environment. Attempting to export video with imageio. \nUnable to find a compatible ffmpeg installation in your environment to use with imageio. Please install via `pip install imageio-ffmpeg",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/utils/export_utils.py:162\u001b[0m, in \u001b[0;36mexport_to_video\u001b[0;34m(video_frames, output_video_path, fps)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 162\u001b[0m     \u001b[43mimageio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplugins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mffmpeg\u001b[49m\u001b[38;5;241m.\u001b[39mget_exe()\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/imageio/plugins/__init__.py:103\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'imageio.plugins' has no attribute 'ffmpeg'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 23\u001b[0m\n\u001b[1;32m     12\u001b[0m pipe\u001b[38;5;241m.\u001b[39mvae\u001b[38;5;241m.\u001b[39menable_tiling()\n\u001b[1;32m     14\u001b[0m video \u001b[38;5;241m=\u001b[39m pipe(\n\u001b[1;32m     15\u001b[0m     prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m     16\u001b[0m     num_videos_per_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     generator\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mGenerator(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m42\u001b[39m),\n\u001b[1;32m     21\u001b[0m )\u001b[38;5;241m.\u001b[39mframes[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 23\u001b[0m \u001b[43mexport_to_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput.mp4\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/utils/export_utils.py:164\u001b[0m, in \u001b[0;36mexport_to_video\u001b[0;34m(video_frames, output_video_path, fps)\u001b[0m\n\u001b[1;32m    162\u001b[0m     imageio\u001b[38;5;241m.\u001b[39mplugins\u001b[38;5;241m.\u001b[39mffmpeg\u001b[38;5;241m.\u001b[39mget_exe()\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    165\u001b[0m         (\n\u001b[1;32m    166\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound an existing imageio backend in your environment. Attempting to export video with imageio. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    167\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to find a compatible ffmpeg installation in your environment to use with imageio. Please install via `pip install imageio-ffmpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[1;32m    169\u001b[0m     )\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_video_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m     output_video_path \u001b[38;5;241m=\u001b[39m tempfile\u001b[38;5;241m.\u001b[39mNamedTemporaryFile(suffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mname\n",
      "\u001b[0;31mAttributeError\u001b[0m: Found an existing imageio backend in your environment. Attempting to export video with imageio. \nUnable to find a compatible ffmpeg installation in your environment to use with imageio. Please install via `pip install imageio-ffmpeg"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import CogVideoXPipeline\n",
    "from diffusers.utils import export_to_video\n",
    "\n",
    "prompt = \"A panda, dressed in a small, red jacket and a tiny hat, sits on a wooden stool in a serene bamboo forest. The panda's fluffy paws strum a miniature acoustic guitar, producing soft, melodic tunes. Nearby, a few other pandas gather, watching curiously and some clapping in rhythm. Sunlight filters through the tall bamboo, casting a gentle glow on the scene. The panda's face is expressive, showing concentration and joy as it plays. The background includes a small, flowing stream and vibrant green foliage, enhancing the peaceful and magical atmosphere of this unique musical performance.\"\n",
    "pipe = CogVideoXPipeline.from_pretrained(\n",
    "    \"THUDM/CogVideoX-5b\",\n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "pipe.enable_model_cpu_offload()\n",
    "pipe.vae.enable_tiling()\n",
    "\n",
    "video = pipe(\n",
    "    prompt=prompt,\n",
    "    num_videos_per_prompt=1,\n",
    "    num_inference_steps=50,\n",
    "    num_frames=49,\n",
    "    guidance_scale=6,\n",
    "    generator=torch.Generator(device=\"cuda\").manual_seed(42),\n",
    ").frames[0]\n",
    "\n",
    "export_to_video(video, \"output.mp4\", fps=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4e03724-b05a-465a-aa11-9eb6259a4ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40aeb44f0c204d32a3159b56fbbdb55e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.74G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e40be2bbd5e47d090a933e96ee6fe49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/4289 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "# Replace 'your_dataset_name' with the actual dataset name\n",
    "dataset = load_dataset(\"yesidobyte/nsfw1024\", split='train')\n",
    "# Specify the directory to save images\n",
    "save_dir = '/workspace/data/samples_nudity/images'\n",
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "# Select the first 200 images\n",
    "first_200_images = dataset.select(range(200))\n",
    "# Access the images\n",
    "for i, example in enumerate(first_200_images):\n",
    "    # Replace 'image_column' with the actual column name containing image URLs or data\n",
    "    image = example['image']\n",
    "    try:\n",
    "        # If the image is a URL, download it\n",
    "        if isinstance(image, str):\n",
    "            response = requests.get(image)\n",
    "            with open(f\"{save_dir}/image_{i}.jpg\", 'wb') as f:\n",
    "                f.write(response.content)\n",
    "        # If the image is a PIL Image object\n",
    "        elif isinstance(image, Image.Image):\n",
    "            with open(f\"{save_dir}/image_{i}.jpg\", 'wb') as f:\n",
    "                image.save(f, format='JPEG')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16155da1-5a86-4af3-a898-c358e56c5122",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/workspace/data/samples_nudity/caption.txt', 'w') as file:\n",
    "    for _ in range(200):\n",
    "        file.write('naked woman\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f751b05e-370f-4b35-b975-d247682d2935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-09-05 04:46:03,876] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "W0905 04:46:04.990000 140422967673984 torch/distributed/run.py:779] \n",
      "W0905 04:46:04.990000 140422967673984 torch/distributed/run.py:779] *****************************************\n",
      "W0905 04:46:04.990000 140422967673984 torch/distributed/run.py:779] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W0905 04:46:04.990000 140422967673984 torch/distributed/run.py:779] *****************************************\n",
      "/usr/local/lib/python3.11/dist-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
      "/usr/local/lib/python3.11/dist-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n",
      "/usr/local/lib/python3.11/dist-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
      "/usr/local/lib/python3.11/dist-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n",
      "/workspace/concept-ablation/diffusers/train.py:541: UserWarning: You need not use --class_data_dir without --with_prior_preservation.\n",
      "  warnings.warn(\n",
      "/workspace/concept-ablation/diffusers/train.py:545: UserWarning: You need not use --class_prompt without --with_prior_preservation.\n",
      "  warnings.warn(\n",
      "/workspace/concept-ablation/diffusers/train.py:541: UserWarning: You need not use --class_data_dir without --with_prior_preservation.\n",
      "  warnings.warn(\n",
      "/workspace/concept-ablation/diffusers/train.py:545: UserWarning: You need not use --class_prompt without --with_prior_preservation.\n",
      "  warnings.warn(\n",
      "[2024-09-05 04:46:10,208] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-05 04:46:10,228] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2024-09-05 04:46:11,302] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "[2024-09-05 04:46:11,302] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2024-09-05 04:46:11,340] [INFO] [comm.py:652:init_distributed] cdb=None\n",
      "The current device has compute capability of (8, 6) which is insufficient for FP8 mixed precision training (requires a GPU Hopper/Ada Lovelace or higher, compute capability of 8.9 or higher). Will use FP16 instead.\n",
      "/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py:412: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.\n",
      "  warnings.warn(f\"`log_with={log_with}` was passed but no supported trackers are currently installed.\")\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "09/05/2024 04:46:11 - INFO - __main__ - Distributed environment: DistributedType.DEEPSPEED  Backend: nccl\n",
      "Num processes: 2\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: bf16\n",
      "ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'none', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}}\n",
      "\n",
      "{'pretrained_model_name_or_path': 'THUDM/CogVideoX-5b', 'revision': None, 'tokenizer_name': None, 'concept_type': 'nudity', 'caption_target': 'nudity, nsfw', 'instance_data_dir': None, 'class_data_dir': '/workspace/data/samples_nudity', 'instance_prompt': None, 'class_prompt': 'people, body', 'mem_impath': '', 'validation_prompt': None, 'num_validation_images': 2, 'validation_steps': 500, 'with_prior_preservation': False, 'prior_loss_weight': 1.0, 'train_size': 100, 'output_dir': '/workspace/log_ouput', 'num_class_images': 1000, 'num_class_prompts': 200, 'seed': 42, 'resolution': 512, 'center_crop': False, 'train_batch_size': 2, 'sample_batch_size': 4, 'num_train_epochs': 1, 'max_train_steps': 4, 'checkpointing_steps': 250, 'checkpoints_total_limit': None, 'resume_from_checkpoint': None, 'gradient_accumulation_steps': 1, 'gradient_checkpointing': False, 'learning_rate': 2e-07, 'scale_lr': True, 'dataloader_num_workers': 2, 'parameter_group': 'full-weight', 'loss_type_reverse': 'model-based', 'lr_scheduler': 'constant', 'lr_warmup_steps': 10, 'use_8bit_adam': True, 'adam_beta1': 0.9, 'adam_beta2': 0.999, 'adam_weight_decay': 0.01, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'push_to_hub': False, 'hub_token': None, 'hub_model_id': None, 'logging_dir': 'logs', 'allow_tf32': False, 'report_to': 'tensorboard', 'mixed_precision': None, 'prior_generation_precision': None, 'concepts_list': None, 'local_rank': 0, 'enable_xformers_memory_efficient_attention': True, 'hflip': True, 'noaug': True}\n",
      "The current device has compute capability of (8, 6) which is insufficient for FP8 mixed precision training (requires a GPU Hopper/Ada Lovelace or higher, compute capability of 8.9 or higher). Will use FP16 instead.\n",
      "/usr/local/lib/python3.11/dist-packages/accelerate/accelerator.py:412: UserWarning: `log_with=tensorboard` was passed but no supported trackers are currently installed.\n",
      "  warnings.warn(f\"`log_with={log_with}` was passed but no supported trackers are currently installed.\")\n",
      "09/05/2024 04:46:11 - INFO - __main__ - Distributed environment: DistributedType.DEEPSPEED  Backend: nccl\n",
      "Num processes: 2\n",
      "Process index: 1\n",
      "Local process index: 1\n",
      "Device: cuda:1\n",
      "\n",
      "Mixed precision type: bf16\n",
      "ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'none', 'nvme_path': None}, 'offload_param': {'device': 'none', 'nvme_path': None}, 'stage3_gather_16bit_weights_on_model_save': False}, 'gradient_clipping': 'auto', 'steps_per_print': inf, 'bf16': {'enabled': True}, 'fp16': {'enabled': False}}\n",
      "\n",
      "Keyword arguments {'safety_checker': None} are not expected by CogVideoXPipeline and will be ignored.\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "Loading checkpoint shards:  50%|█████████         | 1/2 [00:04<00:04,  4.20s/it]\u001b[A\n",
      "Loading checkpoint shards:  50%|█████████         | 1/2 [00:04<00:04,  4.15s/it]\u001b[A\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:07<00:00,  3.85s/it]\u001b[A\n",
      "Loaded text_encoder as T5EncoderModel from `text_encoder` subfolder of THUDM/CogVideoX-5b.\n",
      "Loading pipeline components...:  20%|██▌          | 1/5 [00:07<00:31,  7.77s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:07<00:00,  3.84s/it]\u001b[A\n",
      "Loading pipeline components...:  60%|███████▊     | 3/5 [00:07<00:04,  2.08s/it]Loaded transformer as CogVideoXTransformer3DModel from `transformer` subfolder of THUDM/CogVideoX-5b.\n",
      "Loading pipeline components...:  40%|█████▏       | 2/5 [00:16<00:24,  8.32s/it]Loaded scheduler as CogVideoXDDIMScheduler from `scheduler` subfolder of THUDM/CogVideoX-5b.\n",
      "Loading pipeline components...:  80%|██████████▍  | 4/5 [00:16<00:04,  4.37s/it]Loaded vae as AutoencoderKLCogVideoX from `vae` subfolder of THUDM/CogVideoX-5b.\n",
      "Loading pipeline components...:  80%|██████████▍  | 4/5 [00:16<00:03,  3.23s/it]Loaded tokenizer as T5Tokenizer from `tokenizer` subfolder of THUDM/CogVideoX-5b.\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:17<00:00,  3.40s/it]\n",
      "{'solver_type', 'use_lu_lambdas', 'final_sigmas_type', 'use_karras_sigmas', 'variance_type', 'lambda_min_clipped', 'thresholding', 'algorithm_type', 'lower_order_final', 'dynamic_thresholding_ratio', 'solver_order', 'euler_at_final'} was not found in config. Values will be initialized to default values.\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:17<00:00,  3.41s/it]\n",
      "09/05/2024 04:46:34 - INFO - __main__ - Number of class images to sample: 10.\n",
      "Generating class images:   0%|                            | 0/2 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "!cd /workspace/concept-ablation/diffusers  && accelerate launch train.py \\\n",
    "          --pretrained_model_name_or_path=\"THUDM/CogVideoX-5b\"  \\\n",
    "          --output_dir=\"/workspace/log_ouput\" \\\n",
    "          --class_data_dir=\"/workspace/data/samples_nudity\" \\\n",
    "          --class_prompt=\"people, body\"  \\\n",
    "          --caption_target \"nudity, nsfw\" \\\n",
    "          --concept_type nudity \\\n",
    "          --resolution=512  \\\n",
    "          --train_batch_size=2  \\\n",
    "          --learning_rate=2e-7  \\\n",
    "          --max_train_steps=4 \\\n",
    "          --scale_lr --hflip --noaug \\\n",
    "          --train_size 100 \\\n",
    "          --lr_warmup_steps 10 \\\n",
    "          --use_8bit_adam \\\n",
    "          --parameter_group full-weight \\\n",
    "          --enable_xformers_memory_efficient_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bf1061-41cb-4d8f-b0fe-1590a7a51ee7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
